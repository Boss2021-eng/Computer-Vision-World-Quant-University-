{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the model, let's set up our environment and prepare the data. We'll first load the necessary libraries and print out library versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version :  2.2.2+cu121\n",
      "torchvision version :  0.17.2+cu121\n",
      "torchinfo version :  1.8.0\n",
      "numpy version :  1.26.3\n",
      "matplotlib version :  3.9.2\n",
      "Python 3.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"torchinfo version : \", torchinfo.__version__)\n",
    "print(\"numpy version : \", np.__version__)\n",
    "print(\"matplotlib version : \", matplotlib.__version__)\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check if GPUs are available and set our device accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the `data_p2` directory within which is the `data_undersampled` directory. In that folder we have the `train` subdirectory that contains the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.1:** Assign `data_dir` the path to the training data using `os.path.join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: data_p2/data_undersampled/train\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data_p2\", \"data_undersampled\", \"train\")\n",
    "\n",
    "print(\"Data Directory:\", data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember that images from each class are contained in separate subdirectories within `data_dir`, where the name of each subdirectory is the name of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.2:** Create a list of class names in this data using `os.listdir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of classes: ['cassava-healthy', 'cassava-mosaic-disease-cmd', 'cassava-brown-streak-disease-cbsd', 'cassava-green-mottle-cgm', 'cassava-bacterial-blight-cbb']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(data_dir)\n",
    "\n",
    "print(\"List of classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous lessons, we'll standardize the images using the following set of transformations:\n",
    "\n",
    "- Convert any grayscale images to RGB format with a custom class\n",
    "- Resize the image, so that they're all the same size (we chose $224$ x $224$)\n",
    "- Convert the image to a Tensor of pixel values\n",
    "- Normalize the data\n",
    "\n",
    "Here's the custom transformation that we've used before which converts images to RGB format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToRGB(object):\n",
    "    def __call__(self, img):\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the transformation pipeline. In the normalization step, use the `mean` and `std` values from our previous lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.3:** Create the transformation pipeline using `transforms.Compose` from `torchvision` package. Follow what we did in the previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms.transforms.Compose'>\n",
      "----------------\n",
      "Compose(\n",
      "    <__main__.ConvertToRGB object at 0x7d41a0a7f1d0>\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform_normalized = transforms.Compose(\n",
    "        [\n",
    "        ConvertToRGB(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        # Convert images to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the tensors (copy the mean and std from previous lesson!)\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std= [0.229, 0.224, 0.225])\n",
    "                                              \n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(type(transform_normalized))\n",
    "print(\"----------------\")\n",
    "print(transform_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the dataset and apply our transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.4:** Make a dataset using `ImageFolder` from `datasets` and make sure to apply `transform_normalized` transformation pipeline. Then print the length of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 7615\n"
     ]
    }
   ],
   "source": [
    "normalized_dataset = datasets.ImageFolder(root=data_dir, transform=transform_normalized)\n",
    "\n",
    "\n",
    "print('Length of dataset:', len(normalized_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a train/validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll divide our data into two parts. One part is for training the model, the other part is for evaluating it on unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.5:** Use `random_split` to create a 80/20 split (training dataset should have 80% of the data, validation dataset should have 20% of the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <p><b>About random number generators</b></p>\n",
    "<p>The following cell adds a <code>generator=g</code> line of code that is not present in the video. This is something we have added to make sure you always get the same results in your predictions. Please don't change it or remove it.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataset: 6092\n",
      "Length of validation dataset: 1523\n",
      "Train data is 80.0% of full data\n",
      "Validation data is 20.0% of full data\n"
     ]
    }
   ],
   "source": [
    "# Important, don't change this!\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset = random_split(normalized_dataset, [0.8, 0.2] , generator=g)\n",
    "\n",
    "print(\"Length of training dataset:\", len(train_dataset))\n",
    "print(\"Length of validation dataset:\", len(val_dataset))\n",
    "\n",
    "percent_train = np.round(100 * len(train_dataset) / len(normalized_dataset), 2)\n",
    "percent_val = np.round(100 * len(val_dataset) / len(normalized_dataset), 2)\n",
    "\n",
    "print(f\"Train data is {percent_train}% of full data\")\n",
    "print(f\"Validation data is {percent_val}% of full data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again check how the observations are distributed across classes. We'll reuse the `class_counts` function from `training.py` that we used previously. We want to check the distribution of the training and the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.6:** Use `class_counts` function on the `train_dataset` and visualize the results with a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa67a002edb415497d6b9340707c56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from training import class_counts\n",
    "\n",
    "train_counts = class_counts(train_dataset)\n",
    "\n",
    "# Make a bar chart from the function output\n",
    "train_counts.plot(kind=\"bar\")\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Frequency [count]\")\n",
    "plt.title(\"Distribution of Classes in Training Dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.7:** Use the `class_counts` function on the validation split. Make sure to again visualize the results with a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = class_counts(val_dataset)\n",
    "\n",
    "# Make a bar chart from the function output\n",
    "val_counts.plot(kind=\"bar\")\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Frequency [count]\")\n",
    "plt.title(\"Distribution of Classes in Validation Dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create `DataLoader` objects. We'll use a batch size of 32 and create one `DataLoader` for training and another for validation data. Remember that in training we want to shuffle the data after each epoch and in validation we don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.8:** Create the training loader (with shuffling on) and the validation loader (with shuffling off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "val_loader =  DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(type(train_loader))\n",
    "print(type(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're using Transfer Learning, choosing the right pre-trained model is crucial. We'll select the same model as in the previous lesson. This model has been trained on a large and diverse dataset, ensuring it has learned features that are broadly applicable to various tasks, including ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.9:** Define a `resnet50` model in the same way we defined it in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Transfer Learning, we don't want to tweak the model weights when we train the model on our data. So let's make sure the weights are fixed! \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.10:** Fix the parameters of the model such that they'll not be updated once we train the model on our task. Remember how we did this in the previous lesson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Freeze the models weights\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as we did before, we now want to change the output layer of the model (layer `model.fc`). We want to replace it with a dense layer and an output layer. \n",
    "\n",
    "But we need to know how many features will be going into the dense layer that we want to add. This means we should first compute the number of features going into the last layer of the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.11:** Compute the number of features going into the last layer of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "in_feat = model.fc.in_features\n",
    "\n",
    "print(in_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Now we can change the last layer (layer `model.fc`). We want to change it to:\n",
    "- a dense layer with 256 neurons\n",
    "- followed by ReLU activation\n",
    "- then add `p=0.5` of Dropout\n",
    "- followed by the output layer with 5 neurons (because our data has 5 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.12:** Fill in the missing parts of code below that changes the last layer of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modified_last_layer = nn.Sequential()\n",
    "\n",
    "modified_last_layer.append(nn.Linear(in_feat, 256))\n",
    "\n",
    "relu = nn.ReLU()\n",
    "modified_last_layer.append(relu)\n",
    "\n",
    "modified_last_layer.append(nn.Dropout(p=0.5))\n",
    "\n",
    "linear = nn.Linear(256, 5)\n",
    "modified_last_layer.append(linear)\n",
    "\n",
    "model.fc = modified_last_layer\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the last layer of the model is now different and exactly what we wanted.\n",
    "\n",
    "We're ready to start fitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, before we start training, we need to define the loss and what optimizer we'll use. For loss function we'll go with cross entropy. For the optimizer we'll choose the Adam optimizer as we've done before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.13:** Define cross-entropy as the loss function and set Adam optimizer to be the optimizer. You can use the default learning rate and `weight_decay=1e-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "----------------------\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "\n",
    "print(loss_fn)\n",
    "print(\"----------------------\")\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's make sure that we use the GPU that we have at our disposal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.14:** Place our model on `device`. The code we provided below prints out the device that the model is on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Place model on device\n",
    "model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, let's get more information about our model by calling the `summary` function on the model. You may remember that we've seen this function before. This function requires us to pass in two things: the model itself and the size of input tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.15:** Complete the `input_size` tuple that we are passing to `summary` function in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [32, 5]                   --\n",
       "├─Conv2d: 1-1                            [32, 64, 112, 112]        (9,408)\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        (128)\n",
       "├─ReLU: 1-3                              [32, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-1                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          (4,096)\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 256, 56, 56]         (512)\n",
       "│    │    └─Sequential: 3-9              [32, 256, 56, 56]         (16,896)\n",
       "│    │    └─ReLU: 3-10                   [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-2                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-11                 [32, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-12            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-13                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-14                 [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-15            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-16                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-17                 [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-18            [32, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-19                   [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-3                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-22                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-23                 [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-25                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 56, 56]         --\n",
       "├─Sequential: 1-6                        [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-4                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 128, 56, 56]         (32,768)\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 128, 56, 56]         (256)\n",
       "│    │    └─ReLU: 3-31                   [32, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-32                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-33            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-34                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-35                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-36            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─Sequential: 3-37             [32, 512, 28, 28]         (132,096)\n",
       "│    │    └─ReLU: 3-38                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-5                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-39                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-41                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-42                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-44                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-45                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-47                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-6                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-48                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-49            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-50                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-51                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-52            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-53                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-54                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-55            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-56                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-7                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-57                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-58            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-59                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-60                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-61            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-62                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-63                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-64            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-65                   [32, 512, 28, 28]         --\n",
       "├─Sequential: 1-7                        [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-8                   [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-66                 [32, 256, 28, 28]         (131,072)\n",
       "│    │    └─BatchNorm2d: 3-67            [32, 256, 28, 28]         (512)\n",
       "│    │    └─ReLU: 3-68                   [32, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-69                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-71                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-72                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-73            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─Sequential: 3-74             [32, 1024, 14, 14]        (526,336)\n",
       "│    │    └─ReLU: 3-75                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-9                   [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-76                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-77            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-78                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-79                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-80            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-81                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-82                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-83            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-84                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-10                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-85                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-86            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-87                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-88                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-89            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-90                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-91                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-92            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-93                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-11                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-94                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-95            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-96                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-97                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-98            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-99                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-100                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-101           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-102                  [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-12                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-103                [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-104           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-105                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-106                [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-107           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-108                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-109                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-110           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-111                  [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-13                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-112                [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-113           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-114                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-115                [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-116           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-117                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-118                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-119           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-120                  [32, 1024, 14, 14]        --\n",
       "├─Sequential: 1-8                        [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-14                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-121                [32, 512, 14, 14]         (524,288)\n",
       "│    │    └─BatchNorm2d: 3-122           [32, 512, 14, 14]         (1,024)\n",
       "│    │    └─ReLU: 3-123                  [32, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-124                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-125           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-126                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-127                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-128           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─Sequential: 3-129            [32, 2048, 7, 7]          (2,101,248)\n",
       "│    │    └─ReLU: 3-130                  [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-15                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-131                [32, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-132           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-133                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-134                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-135           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-136                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-137                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-138           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-139                  [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-16                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-140                [32, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-141           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-142                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-143                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-144           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-145                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-146                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-147           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-148                  [32, 2048, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --\n",
       "├─Sequential: 1-10                       [32, 5]                   --\n",
       "│    └─Linear: 2-17                      [32, 256]                 524,544\n",
       "│    └─ReLU: 2-18                        [32, 256]                 --\n",
       "│    └─Dropout: 2-19                     [32, 256]                 --\n",
       "│    └─Linear: 2-20                      [32, 5]                   1,285\n",
       "==========================================================================================\n",
       "Total params: 24,033,861\n",
       "Trainable params: 525,829\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (Units.GIGABYTES): 130.81\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5690.43\n",
       "Params size (MB): 96.14\n",
       "Estimated Total Size (MB): 5805.83\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "\n",
    "summary(model, input_size=(batch_size, 3, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other things, the output of the summary displays the amount of trainable parameters the model has. And it has many! \n",
    "\n",
    "While we added Dropout, which helps with preventing overfitting, we'll go further and take another step to make sure we don't overfit. When we fit, we'll check model performance at every epoch and stop fitting when the model stops improving. This brings us to callbacks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model with Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training of our model, we can use various callbacks. Callbacks allow us to customize and control the training process in fine-grained ways. We'll implement three key callbacks:\n",
    "        \n",
    "- **Learning Rate Scheduling**: Adjusts the learning rate over time, which can lead to better model performance.\n",
    "- **Early Stopping**: Halts training when the model's performance stops improving, which prevents overfitting. We'll stop if validation loss doesn't improve for at least 5 epochs.\n",
    "- **Checkpointing**: Saves the model every time validation loss gets better than in the epoch prior. This allows us to recover the best model once training completes.\n",
    "\n",
    "In order to use these callbacks, we need to implement them and then update the `train` function. \n",
    "\n",
    "For the Learning Rate Scheduling, we'll use `StepLR` from `torch.optim`. The `StepLR` scheduler decays the learning rate by multiplicative factor `gamma` every `step_size` epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.16:** Set `step_size` to $4$ and `gamma` factor to $0.2$. The rest of the code creates a `StepLR` Learning Rate Scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.lr_scheduler.StepLR'>\n"
     ]
    }
   ],
   "source": [
    "# Period of learning rate decay\n",
    "step_size = 4\n",
    "# Multiplicative factor of learning rate decay\n",
    "gamma = 0.2\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler = StepLR(\n",
    "    optimizer,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma,\n",
    ")\n",
    "\n",
    "print(type(scheduler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Early Stopping, we'll create a function `early_stopping` that we'll call from within the `train` function. The `early_stopping` function accepts:\n",
    "- the current validation loss,\n",
    "- the best validation loss so far\n",
    "- the number of epochs since validation loss last improved (counter).\n",
    "\n",
    "In the function we need to check if validation loss improved. If yes, we reset the counter. If not, we add one to the counter. We also need to check if validation loss hasn't improved in the last 5 epochs. If that is the case, we should set stopping to `True`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.17:** Fill in the missing code in the definition of the `early_stopping` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Function that implements Early Stopping\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_19/2061997087.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def early_stopping(validation_loss, best_val_loss, counter):\n",
    "    \"\"\"Function that implements Early Stopping\"\"\"\n",
    "\n",
    "    stop = False\n",
    "\n",
    "    if validation_loss < best_val_loss:\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # Check if counter is >= patience (5 epochs in our case)\n",
    "    # Set stop variable accordingly\n",
    "    if counter >= 5:\n",
    "        stop=True\n",
    "\n",
    "    return counter, stop\n",
    "\n",
    "\n",
    "early_stopping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define a function that will take care of Checkpointing. In this function we need to check if validation loss improved. If yes, we save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpointing(validation_loss, best_val_loss, model, optimizer, save_path):\n",
    "\n",
    "    if validation_loss < best_val_loss:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": best_val_loss,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"Checkpoint saved with validation loss {validation_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to modify the `train` function to include an option to use Callbacks. \n",
    "\n",
    "Notice that the modified `train` function below is quite similar to what we've used before. We just added `scheduler`, `checkpoint_path` and `early_stopping` as optional arguments. As you can see at the end of the modified `train` function, we use these three callbacks when function is called with appropriate inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import score, train_epoch\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=20,\n",
    "    device=\"cpu\",\n",
    "    scheduler=None,\n",
    "    checkpoint_path=None,\n",
    "    early_stopping=None,\n",
    "):\n",
    "    # Track the model progress over epochs\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    learning_rates = []\n",
    "\n",
    "    # Create the trackers if needed for checkpointing and early stopping\n",
    "    best_val_loss = float(\"inf\")\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    print(\"Model evaluation before start of training...\")\n",
    "    # Test on training set\n",
    "    train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    # Test on validation set\n",
    "    validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
    "    val_losses.append(validation_loss)\n",
    "    val_accuracies.append(validation_accuracy)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"\\n\")\n",
    "        print(f\"Starting epoch {epoch}/{epochs}\")\n",
    "\n",
    "        # Train one epoch\n",
    "        train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
    "\n",
    "        # Evaluate training results\n",
    "        train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Test on validation set\n",
    "        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
    "        val_losses.append(validation_loss)\n",
    "        val_accuracies.append(validation_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.4f}%\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print(f\"Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
    "\n",
    "        # # Log the learning rate and have the scheduler adjust it\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        learning_rates.append(lr)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Checkpointing saves the model if current model is better than best so far\n",
    "        if checkpoint_path:\n",
    "            checkpointing(\n",
    "                validation_loss, best_val_loss, model, optimizer, checkpoint_path\n",
    "            )\n",
    "\n",
    "        # Early Stopping\n",
    "        if early_stopping:\n",
    "            early_stopping_counter, stop = early_stopping(\n",
    "                validation_loss, best_val_loss, early_stopping_counter\n",
    "            )\n",
    "            if stop:\n",
    "                print(f\"Early stopping triggered after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "        if validation_loss < best_val_loss:\n",
    "            best_val_loss = validation_loss\n",
    "\n",
    "    return (\n",
    "        learning_rates,\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "        train_accuracies,\n",
    "        val_accuracies,\n",
    "        epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model and callbacks ready, we'll proceed to train the model. During this phase, we'll observe how callbacks affect the training process and ultimately, the model's performance. \n",
    "\n",
    "Because we implemented early stopping, the model will stop training once its performance no longer improves. So we can set off to train for many epochs and training will stop when the model stops improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.18:** Define the number of training epochs to equal 50. The rest of the code provided below will call the `train` function and start the training. Note that this can take a while to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> <strong>Regarding Model Training Times</strong>\n",
    "\n",
    "This task involves training the model for (at least) 50 epochs. This might take more than 60 minutes. Instead, we recommend you to skip the training process and load the pre-trained model that we have made available in the next few cells.\n",
    "\n",
    "<b>We strongly recommend you to use the saved model instead of training your own</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_train = ...\n",
    "\n",
    "train_results = train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=epochs_to_train,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    checkpoint_path=\"model/LR_model.pth\",\n",
    "    early_stopping=early_stopping,\n",
    ")\n",
    "\n",
    "(\n",
    "    learning_rates,\n",
    "    train_losses,\n",
    "    valid_losses,\n",
    "    train_accuracies,\n",
    "    valid_accuracies,\n",
    "    epochs,\n",
    ") = train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[RECOMMENDED]** Load the pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model = torch.load(\"model_trained.pth\", weights_only=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the training indeed didn't go over all 50 epochs, but stopped earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training went on for {epochs} number of epochs before it stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Training Process and the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training's finished, we'll evaluate our model's performance and draw conclusions. We'll see how effectively our callbacks contributed to the training process and discuss the results. Let's first plot the learning curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_metrics_df = pd.read_csv(\"pretrained_model_evaluation_metrics.csv\")\n",
    "train_losses = eval_metrics_df['train_losses'].values\n",
    "valid_losses = eval_metrics_df['valid_losses'].values\n",
    "train_accuracies = eval_metrics_df['train_accuracies'].values\n",
    "valid_accuracies = eval_metrics_df['valid_accuracies'].values\n",
    "learning_rates = eval_metrics_df['learning_rates'].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(valid_losses, label=\"Validation Loss\")\n",
    "plt.ylim([0, 1.7])\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.19:** Complete the code below to plot train and validation accuracies. You can follow what we did above for plotting train and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train accuracies, use label=\"Training Accuracy\"\n",
    "\n",
    "# Plot validation accuracies, use label=\"Validation Accuracy\"\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.title(\"Accuracy over epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the learning curve we see that overall training loss decreases and accuracy increases. Validation loss does not seem to improve that much beyond the first couple of epochs.\n",
    "\n",
    "Let's also inspect how the learning rate was changing during training due to the fact that we used a Learning Rate Scheduling Callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), learning_rates, marker=\"o\", label=\"Learning Rate\")\n",
    "plt.title(\"Learning Rate Schedule\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the learning rate decreases as our training progresses.\n",
    "\n",
    "Now it's time load the best model that we saved with checkpointing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model/LR_model.pth\")\n",
    "\n",
    "# Load the state dictionaries\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the confusion matrix for our model using the validation data, like we did in previous lessons.\n",
    "\n",
    "We'll obtain the probabilities that our model predicts by using the `predict` function from `training.py`. This function expects the model, the loader and the device as input arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.20:** Use the `predict` function from `training.py` to compute probabilities that our model predicts on the validation data. Then use `torch.argmax` and take these probabilities to compute the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import predict\n",
    "\n",
    "probabilities_val = ...\n",
    "predictions_val = ...\n",
    "\n",
    "print(predictions_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get the target values and compute the confusion matrix. Again, same as we've done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_val = torch.cat([labels for _, labels in tqdm(val_loader, desc=\"Get Labels\")])\n",
    "\n",
    "cm = confusion_matrix(targets_val.cpu(), predictions_val.cpu())\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done, looks good! We're ready to use this model on our test set and prepare a CSV file that we can submit to the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition submission should contain predicted probabilities for each of the $5$ classes on a test set. So we'll need to run each test image through our model.\n",
    "\n",
    "Let's first find the test images. They are located in the `test` subdirectory within the `data_p2` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.21:** Assign `test_dir` the path to the test data using `os.path.join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = ...\n",
    "\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition requires us to save the model predictions as a CSV file. The first column should be called ID and contains the image filename. The rest of the columns should be labeled by the class name.\n",
    "\n",
    "In order to get predicted probabilities of our model, we'll create a function `file_to_confidence` which is similar to what we created for this purpose in Project 1. The function makes model predictions on a single image. The steps in the function are:\n",
    "- Open the image.\n",
    "- Apply our transformation pipeline to the image as our model expects.\n",
    "- Use `unsqueeze` to change the image tensor to 4D ($1$ x $3$ x $224$ x $224$) as our model is expecting a batch of images.\n",
    "- Place image on device we're using.\n",
    "- Make prediction and pass it through a `SoftMax` to get probabilities (numbers between $0$ and $1$, that sum to $1$).\n",
    "- Convert result to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "\n",
    "def file_to_confidence(model, datadir, filename, transform_pipeline):\n",
    "    file_path = os.path.join(datadir, filename)\n",
    "    image = PIL.Image.open(file_path)\n",
    "    transformed = transform_pipeline(image)\n",
    "    unsqueezed = transformed.unsqueeze(0)\n",
    "    image_cuda = unsqueezed.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_raw = model(image_cuda)\n",
    "        confidence = torch.nn.functional.softmax(model_raw, dim=1)\n",
    "\n",
    "    conf_df = pd.DataFrame([[filename] + confidence.tolist()[0]])\n",
    "    conf_df.columns = [\"ID\"] + train_dataset.dataset.classes\n",
    "\n",
    "    return conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure this is working, let's call this function on a training image from the cassava mosaic disease class for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_train_dir = os.path.join(\"data_p2\", \"train\", \"cassava-mosaic-disease-cmd\")\n",
    "mosaic_images = os.listdir(mosaic_train_dir)\n",
    "\n",
    "file_to_confidence(model, mosaic_train_dir, mosaic_images[0], transform_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks alright! The largest predicted probability on this mosaic image is for the mosaic disease class.\n",
    "\n",
    "Let's try one more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_confidence(model, mosaic_train_dir, mosaic_images[1], transform_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems in order. Now let's use `file_to_confidence` function on each test image to get the predictions for the competition submission. We can loop over the filenames and build up a list of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5.22:** Fill in the missing code below and use `pd.concat` to assemble the list of DataFrames `small_dfs` into one big DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dfs = []\n",
    "\n",
    "for filename in tqdm(os.listdir(test_dir), desc=\"Predicting on test set\"):\n",
    "    small_dfs.append(\n",
    "        file_to_confidence(model, test_dir, filename, transform_normalized)\n",
    "    )\n",
    "\n",
    "confidence_df = ...\n",
    "\n",
    "confidence_df = confidence_df.sort_values(\"ID\").reset_index(drop=True)\n",
    "confidence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the dataframe as a CSV in `submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! 🎉 We accomplished a lot in this notebook. Here are the key takeaways:\n",
    "\n",
    "- We used Transfer Learning to take a large existing model and specialize it to our competition.\n",
    "- We trained that model with the balanced dataset we created in an earlier lesson.\n",
    "- We implemented Callbacks using additional code in the training loop.\n",
    "- The Callbacks we implemented were: Learning Rate Scheduling, Checkpointing, and Early Stopping.\n",
    "- By reformatting the predictions of the model on the test set, we obtained a CSV file for competition submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "21046566f9f642e29c20acf9b6d34085": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "22da743f23fd44de99676b1ea01444a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2f53e02ad4884887a24e79e6394f2d0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4fa67a002edb415497d6b9340707c56e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9185c28684a849b7aa9b38e305c3eb35",
        "IPY_MODEL_f309c7b4bcff44549815b8ffcbfa2b17",
        "IPY_MODEL_8c7f5e3873b64ce8b18d81eb8cb87d02"
       ],
       "layout": "IPY_MODEL_9bf453e1542d4f35a5b7c6223a72d954"
      }
     },
     "712748be096346d9a8df5325cca961f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8c7f5e3873b64ce8b18d81eb8cb87d02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_22da743f23fd44de99676b1ea01444a6",
       "style": "IPY_MODEL_2f53e02ad4884887a24e79e6394f2d0f",
       "value": " 6092/6092 [01:33&lt;00:00, 65.72it/s]"
      }
     },
     "9185c28684a849b7aa9b38e305c3eb35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dbebebf625964a268a20c91602a5bff9",
       "style": "IPY_MODEL_21046566f9f642e29c20acf9b6d34085",
       "value": "100%"
      }
     },
     "9bf453e1542d4f35a5b7c6223a72d954": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dbebebf625964a268a20c91602a5bff9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f19965031f1c4d639967af381c993fe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f309c7b4bcff44549815b8ffcbfa2b17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f19965031f1c4d639967af381c993fe8",
       "max": 6092,
       "style": "IPY_MODEL_712748be096346d9a8df5325cca961f9",
       "value": 6092
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
